{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Opdrachten\n",
    "==========\n",
    "\n",
    "Vraag 1 - Accuarcy, Precision, Recall, F-measure\n",
    "-------------------------------------------------\n",
    "\n",
    "In de tabel hieronder vind je de confusion matrix van een binaire classifier.\n",
    "\n",
    "|     &nbsp;    | Actual NO |  Actual YES|           |\n",
    "|---------------|:---------:|:----------:|:---------:|\n",
    "|Predicted NO   |50         | 5          |  **55**   |\n",
    "|Predicted YES  |10         | 100        |  **110**  |\n",
    "|     &nbsp;    |**60**     | **105**    |  ***165***|\n",
    "\n",
    "\n",
    "Beantwoord nu de volgende vragen:\n",
    "\n",
    "a) Wat zijn de waarden voor TP, TN, FP, FN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "b) Bereken nu handmatig de accuracy, precision en recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "c) Bereken de $F_1$ en $F_{1.5}$-measures. Schrijf het resultaat op met 2 significantiecijfers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "d) Wat is de TPR en FPR? Vergelijk met je recall. Wat stel je vast?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Schrijf functies in Python die bovenstaande metrieken kunnen berekenen uit een confusion matrix. Maak hiervoor een apart Python bestand aan dat je import in deze Jupyter Notebook.\n",
    "\n",
    "Let op: dit lukt niet met bestaande functies uit <code>sklearn.metrics</code>, want die werken op de ruwe gegevens en niet op een al bestaande confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a) Maak van bovenstaande tabel een (confusion) matrix in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "b) Schrijf een aparte functie voor elk metriek en controleer je oplossing.\n",
    "    Zoek eerst de werking op van volgende functies in Python:\n",
    "```python\n",
    "np.diag\n",
    "np.sum(axis=0 of 1)\n",
    "map\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vraag 2 - Accuarcy, Precision, Recall, F-measure\n",
    "-------------------------------------------------\n",
    "\n",
    "In de tabel hieronder vind je de confusion matrix van een binaire classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "|&nbsp;       |   Actual A |   Actual B |           |\n",
    "|:------------|:----------:|:----------:|:---------:|\n",
    "| Predicted A |        100 |         50 |**150**    |\n",
    "| Predicted B |          0 |          5 |**5**      |\n",
    "| &nbsp;      |    **100** |     **55** |**150**  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a) Wat zijn de waarden voor TP, TN, FP, FN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "b) Bereken met je Python-functies de accuracy, precision en recall, en $F_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c) Is dit een goede classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Vraag 3 - Accuarcy, Precision, Recall, F-measure\n",
    "-------------------------------------------------\n",
    "\n",
    "In de tabel hieronder vind je de confusion matrix van een multiclass classifier.\n",
    "\n",
    "|              &nbsp;   | &nbsp; | &nbsp; | **Werkelijke klasse** | &nbsp; |&nbsp;|&nbsp;|&nbsp;|\n",
    "| --------------------- |:------:| :----: | :-------------------: | :--: | :--: | :----: | ---- |\n",
    "|     &nbsp;            | &nbsp; | Asfalt |         Beton         | Gras | Boom | Gebouw |      |\n",
    "| **Voorspelde klasse** | Asfalt |  2385  |           4           |  0   |  1   |   4    | 2394 |\n",
    "|     &nbsp;            | Beton  |   0    |          332          |  0   |  0   |   1    | 333  |\n",
    "|     &nbsp;            | Gras   |   0    |           1           | 908  |  8   |   0    | 917  |\n",
    "|     &nbsp;            | Boom   |   0    |           0           |  0   | 1084 |   9    | 1093 |\n",
    "|     &nbsp;            | Gebouw |   12   |           0           |  0   |  6   |  2053  | 2071 |\n",
    "|     &nbsp;            | &nbsp; |  2397  |          337          | 908  | 1099 |  2067  | 6808 |\n",
    "\n",
    "Beantwoord nu de volgende vragen:\n",
    "\n",
    "a) Wat zijn de waarden voor TP, TN, FP, FN voor de klasse Gras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pas je functies voor alle evaluatiemetrieken aan zodat ze o.b.v. een extra parameter (global=T/F) ófwel een globale waarde retourneren ófwel de waarde per klasse. De globale waarde kun je berekenen als het gewogen gemiddelde van alle per klasse waarden.\n",
    "\n",
    "b) Bereken nu de accuracy, precision en recall per klasse met deze functies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "c) Is dit een goede classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vraag 4 - ROC Curves - The Simpsons\n",
    "-----------------------------------\n",
    "\n",
    "De SciKit Learn package <code>sklearn.metrics</code> bevat een functie <code>roc_curve</code> om ROC curves te laten berekenen. We gaan deze gebruiken om de kwaliteit van een **binaire classifier** te controleren.\n",
    "\n",
    "Lees de gegevens de gegevens uit simpsons_roc1 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a) Schrijf een functie die ROC-curve m.b.v. matplotlib kan plotten door de FPR en TPR-waarden tegenover elkaar uit te plotten. Gebruik matplotlib, en roc_curve en roc_auc_score uit sklearn.metrics dit te doen. Op sklearn vind je ook een voorbeeld van hoe je dit kan realiseren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "b) Wat is de beste threshold-waarde?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "c) Wat is de AUC? Wat betekent dit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "d) Pas de gevonden threshold-toe op de y_score kolom (deze kolom is in feite de uitkomst van de predict_proba-functie van een neuraal netwerk, zie neurale netwerken) om een nieuwe kolom predicted te maken.\n",
    "\n",
    "e) Herhaal stappen a tot d maar maar op de gegevens uit de simpsons_roc2 dataset. Welke verschillen merk je op?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vraag 5 - ROC Curves - Infertility\n",
    "----------------------------------\n",
    "\n",
    "a) Laad de dataset education_roc1 en education_roc2. Ze bevatten de scores van twee modellen voor de binaire klassificatie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "e) Maak nu twee ROC-modellen voor elk van de voorspellingen m.b.v. de roc-functie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "f) Plot de ROC-curves met de beste threshold-waarde en hun respectievelijke AUC's. op één en dezelfde grafiek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "g) Wat concludeer je?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inzichtsvragen\n",
    "--------------\n",
    "\n",
    "a) Heeft de initiële klasse-verdeling (bvb. #positieven vs. #niet-positieven bij binaire classifier) in een dataset een invloed op kwaliteit van de classifier? Verklaar dit.\n",
    "\n",
    "b) Welke evaluatiemetriek(en) kunnen deze invloed detecteren? Welke niet? Waarom?\n",
    "\n",
    "c) Hoe kun je dit probleem oplossen?\n",
    "\n",
    "d) Waar ligt de beste threshold-waarde op een ROC-curve? Waarom is dit?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}